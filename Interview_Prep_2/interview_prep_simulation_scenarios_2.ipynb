{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohith200023/AI_Interview_Assist/blob/main/Interview_Prep_2/interview_prep_simulation_scenarios_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Lifecycle Walkthrough\n",
        "\n",
        "Name\n"
      ],
      "metadata": {
        "id": "4SUvtSLX7Zcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "In this assignment, you will be provided a randomly generated dataset that you will need to clean, prepare, do an exploratory data analysis on, and fit both a linear and logistic regression model. First thing is to run this notebook as is. The code in this notebook generates some messy data and two dependent variables, one for a linear regression model, and one for a logistic regression model. After you run the notebook, then continue to the Data Prep Process and complete the rest of the notebook. You are also asked to select the 5 most important features, and evaluate your models using appropriate metrics. Be sure to be able to explain the rational for each action you take. Finally provide a summary at the end of the notebook that let's your future boss know your analysis and findings."
      ],
      "metadata": {
        "id": "gMnhciXkKOoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started\n",
        "\n",
        "* Save a Copy in Drive\n",
        "* Remove Copy of in filename\n",
        "* Edit your name\n",
        "* Clean up Colab Notebooks folder\n",
        "* Submit shared link\n",
        "* Do all your work in this notebook\n",
        "* Run this notebook as is so you can get your simulated dataset\n",
        "* **CLICK ON THE `Run all` BUTTON IN THE MENU TO GET STARTED**\n",
        "* Once you run this notebook you will find your simulated dataset in the session storage (click on the folder icon in the left panel)\n",
        "* Be aware that each time this notebook is executed will result in a new simulated data csv file\n",
        "* Go through the **Create Data** section to get familiar with the data\n",
        "* Start your code and cleaning in the **Data Prep Process** section and complete the rest of the notebook"
      ],
      "metadata": {
        "id": "tv86CANY3_Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keep in mind**\n",
        "\n",
        "* If your model metrics are too high, almost perfect, find and remove features that are have a near perfect relationship with the DV. Document your rational.\n",
        "\n",
        "**PII Fields**\n",
        "\n",
        "* Names, email, phone, full address, and exact DOB are being generated. PII should be removed or transformed (hashing/tokenizing, extracting non-identifying parts like state or age-in-years) before modeling. Justify your actions.\n",
        "\n",
        "**Missingness**\n",
        "\n",
        "* Because missingness is injected across many columns at varying percentages, review MCAR, MNAR, and MAR and document your plan to drop vs impute; and document why.\n",
        "\n",
        "**Data Hygiene Goals**\n",
        "\n",
        "* Handle duplicates, PII, outliers, missingness, and type casting. Briefly justify each decision.\n",
        "\n",
        "**Train/Validation Protocol**\n",
        "\n",
        "* Use a proper holdout or cross-validation. Fit encoders/imputers on **train only** and apply to validation/test. State the split logic (stratified for classification if imbalance exists).\n",
        "\n",
        "**Leakage and Bias Checks**\n",
        "\n",
        "* Explicitly identify potential leakage sources, and discuss whether demographic variables should be included, excluded, or aggregated—and why."
      ],
      "metadata": {
        "id": "fTsjis1uSAVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prep Introduction\n",
        "\n",
        "* Types and characteristics of data\n",
        "* Duplicates\n",
        "* Constants\n",
        "* Quasi-Constants\n",
        "* Missing data\n",
        "* Outliers\n",
        "* Datetime\n",
        "* Feature creation\n",
        "* Discretization\n",
        "* Categorical encoding\n",
        "* Variable transformation\n",
        "* Scaling\n",
        "\n",
        "When performing data preparation, the order of operations is crucial for a robust and reproducible machine learning pipeline. While there isn't one single \"best\" order that fits every scenario, a logical and widely accepted sequence follows a general flow from broad data quality checks to more specific feature transformations. This ensures that early steps, like removing bad data, don't get skewed by later transformations.\n",
        "\n",
        "The general best-practice order is:\n",
        "\n",
        "1.  **Remove Bad Data and Redundancy:** Begin by identifying and removing data that's problematic at a fundamental level.\n",
        "    * **Duplicates**: Removing duplicate rows is the first step. They can bias a model and inflate performance metrics.\n",
        "    * **Constants**: Columns with only one unique value (constants) provide no information for a model to learn from. Removing them early reduces dimensionality and simplifies your dataset.\n",
        "    * **Quasi-Constants**: Similar to constants, these features have very little variance (e.g., 99% of values are the same). It's generally a good idea to remove them as they offer minimal predictive power.\n",
        "\n",
        "2.  **Handle Missing Data and Outliers:** Once your data is free of redundant rows and features, you can address quality issues within the remaining columns.\n",
        "    * **Missing Data**: Decide on a strategy for handling missing values. This can involve dropping rows or columns with too much missing data, or **imputing** values using methods like the mean, median, or more advanced techniques.\n",
        "    * **Outliers**: After addressing missing data, identify and handle outliers. Outliers can heavily influence the mean and other statistics, so it's important to deal with them before transformations or scaling.\n",
        "\n",
        "3.  **Perform Feature Engineering:** This is a creative and domain-specific step where you can extract more information from your existing features.\n",
        "    * **Datetime**: Extracting meaningful features from datetime columns, such as month, day of the week, or holiday flags, is a common and powerful technique. This should be done before more generic transformations.\n",
        "    * **Feature Creation**: This is the core of feature engineering, where you create new variables based on your domain knowledge. For example, creating a `BMI` feature from `height` and `weight`.\n",
        "\n",
        "4.  **Transform Variables and Features:** With a clean and feature-rich dataset, you can now prepare the variables for the specific requirements of your chosen model.\n",
        "    * **Discretization**: If needed, convert continuous numerical features into discrete bins. This is often used for algorithms that benefit from binned data, like certain tree-based models.\n",
        "    * **Categorical Encoding**: Convert all categorical features (which may have been `object` or `category` data types) into a numerical format. This is a non-negotiable step for most machine learning algorithms. The choice between one-hot encoding, label encoding, etc., depends on the nature of the data.\n",
        "\n",
        "5.  **Scale Features:** The final step before training a model is often scaling, which adjusts the range of numerical features.\n",
        "    * **Scaling**: This is especially important for distance-based algorithms like **K-nearest Neighbors** and models that use gradient descent, such as **Linear Regression** and **Neural Networks**. Common techniques are **Normalization** (Min-Max Scaling) and **Standardization** (Z-Score Scaling). This should be done **after** all other transformations to prevent data leakage and ensure the scaling is based on the final, prepared feature values.\n"
      ],
      "metadata": {
        "id": "p43IcKZ2H4TU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Data"
      ],
      "metadata": {
        "id": "RpWcbBh6rAKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seed the Project"
      ],
      "metadata": {
        "id": "FMVaAmuqAWhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_user_seed():\n",
        "    # Get current time in nanoseconds (more granular)\n",
        "    nanoseconds = time.time_ns()\n",
        "\n",
        "    # Add a small random component to further reduce collision chances\n",
        "    random_component = random.randint(0, 1000)  # Adjust range as needed\n",
        "\n",
        "    # Combine them (XOR is a good way to mix values)\n",
        "    seed = nanoseconds ^ random_component\n",
        "\n",
        "    # Ensure the seed is within the valid range for numpy's seed\n",
        "    seed = seed % (2**32)  # Modulo to keep it within 32-bit range\n",
        "\n",
        "    return seed\n",
        "\n",
        "user_seed = generate_user_seed()\n",
        "print(user_seed)\n",
        "random_state = np.random.seed(user_seed)"
      ],
      "metadata": {
        "id": "YUMcsfNhXbRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "56d72df8-6e08-4718-8135-2279ea326106"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "981142940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Faker"
      ],
      "metadata": {
        "id": "_j1l2Lr8_bS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Faker -q"
      ],
      "metadata": {
        "id": "hViR5zhSGxq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3aac442f-0337-4293-c4cd-7e19db91522f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_names=[\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"]"
      ],
      "metadata": {
        "id": "Qpa4mbcgKoEb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create demographic data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "fake = Faker()\n",
        "\n",
        "output = []\n",
        "for x in range(1000):\n",
        "  binary = np.random.choice(['binary_1', 'binary_2'], p=[0.5, 0.5])\n",
        "  output.append({\n",
        "        'binary': binary, # sex assigned at birth\n",
        "        'given_name': fake.first_name_female() if binary=='binary_1' else fake.first_name_male(),\n",
        "        'datetime': fake.date_time_this_decade(),\n",
        "        'surname': fake.last_name(),\n",
        "        'date_of_birth': fake.date_of_birth(),\n",
        "        'day_of_week': fake.day_of_week(),\n",
        "        'phone_number': fake.phone_number(),\n",
        "        'email': fake.email(),\n",
        "        'address': fake.address(),\n",
        "        'city': fake.city(),\n",
        "        'state': np.random.choice(state_names),\n",
        "        'zipcode': fake.zipcode(),\n",
        "        })\n",
        "\n",
        "demographics = pd.DataFrame(output)\n",
        "demographics.head()"
      ],
      "metadata": {
        "id": "HqvkXvuWKbXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "638d6177-e715-41f1-c2c1-f848ce1a08aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     binary given_name                   datetime   surname date_of_birth  \\\n",
              "0  binary_1   Danielle 2021-09-18 11:06:40.740474  Gonzalez    1937-05-08   \n",
              "1  binary_1      Ellen 2023-10-26 22:35:16.736140     Allen    1984-08-24   \n",
              "2  binary_2    Matthew 2024-05-01 00:21:23.998693     Flynn    1933-01-01   \n",
              "3  binary_2     Donald 2025-06-21 01:58:05.375285    Vaughn    1924-02-04   \n",
              "4  binary_1      Kathy 2024-07-08 17:00:40.824699  Crawford    1919-04-11   \n",
              "\n",
              "  day_of_week          phone_number                    email  \\\n",
              "0     Tuesday  001-510-723-9903x368    heathbeth@example.net   \n",
              "1      Friday          223-357-6164  scottashlee@example.org   \n",
              "2      Friday      699-323-3336x981    sabrina73@example.org   \n",
              "3   Wednesday          461.337.7790      jason36@example.net   \n",
              "4      Sunday          514-230-6439  cherylhorne@example.org   \n",
              "\n",
              "                                             address              city  \\\n",
              "0                   PSC 2623, Box 0648\\nAPO AE 79751       Murillofort   \n",
              "1    354 Stacey Parks Apt. 728\\nLake Kevin, FL 06933  West Jasminefurt   \n",
              "2                   Unit 0942 Box 1965\\nDPO AE 52063        Orozcoside   \n",
              "3  005 Gonzalez Fords Suite 160\\nMooreborough, WY...       Edwardshire   \n",
              "4             867 John River\\nLake Michael, SD 38874      Kristinville   \n",
              "\n",
              "      state zipcode  \n",
              "0      Utah   61629  \n",
              "1   Indiana   77087  \n",
              "2   Montana   90582  \n",
              "3  Michigan   99518  \n",
              "4   Vermont   37836  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a3b136a-51af-4992-8d9d-96a9751f2b2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary</th>\n",
              "      <th>given_name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>surname</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>phone_number</th>\n",
              "      <th>email</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Danielle</td>\n",
              "      <td>2021-09-18 11:06:40.740474</td>\n",
              "      <td>Gonzalez</td>\n",
              "      <td>1937-05-08</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>001-510-723-9903x368</td>\n",
              "      <td>heathbeth@example.net</td>\n",
              "      <td>PSC 2623, Box 0648\\nAPO AE 79751</td>\n",
              "      <td>Murillofort</td>\n",
              "      <td>Utah</td>\n",
              "      <td>61629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>2023-10-26 22:35:16.736140</td>\n",
              "      <td>Allen</td>\n",
              "      <td>1984-08-24</td>\n",
              "      <td>Friday</td>\n",
              "      <td>223-357-6164</td>\n",
              "      <td>scottashlee@example.org</td>\n",
              "      <td>354 Stacey Parks Apt. 728\\nLake Kevin, FL 06933</td>\n",
              "      <td>West Jasminefurt</td>\n",
              "      <td>Indiana</td>\n",
              "      <td>77087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Matthew</td>\n",
              "      <td>2024-05-01 00:21:23.998693</td>\n",
              "      <td>Flynn</td>\n",
              "      <td>1933-01-01</td>\n",
              "      <td>Friday</td>\n",
              "      <td>699-323-3336x981</td>\n",
              "      <td>sabrina73@example.org</td>\n",
              "      <td>Unit 0942 Box 1965\\nDPO AE 52063</td>\n",
              "      <td>Orozcoside</td>\n",
              "      <td>Montana</td>\n",
              "      <td>90582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Donald</td>\n",
              "      <td>2025-06-21 01:58:05.375285</td>\n",
              "      <td>Vaughn</td>\n",
              "      <td>1924-02-04</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>461.337.7790</td>\n",
              "      <td>jason36@example.net</td>\n",
              "      <td>005 Gonzalez Fords Suite 160\\nMooreborough, WY...</td>\n",
              "      <td>Edwardshire</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>99518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Kathy</td>\n",
              "      <td>2024-07-08 17:00:40.824699</td>\n",
              "      <td>Crawford</td>\n",
              "      <td>1919-04-11</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>514-230-6439</td>\n",
              "      <td>cherylhorne@example.org</td>\n",
              "      <td>867 John River\\nLake Michael, SD 38874</td>\n",
              "      <td>Kristinville</td>\n",
              "      <td>Vermont</td>\n",
              "      <td>37836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a3b136a-51af-4992-8d9d-96a9751f2b2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a3b136a-51af-4992-8d9d-96a9751f2b2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a3b136a-51af-4992-8d9d-96a9751f2b2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "demographics",
              "summary": "{\n  \"name\": \"demographics\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"binary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"binary_2\",\n          \"binary_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"given_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 362,\n        \"samples\": [\n          \"Kristen\",\n          \"Nicholas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-01 19:10:50.692840\",\n        \"max\": \"2026-01-31 06:25:39.393294\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2022-06-17 11:39:28.240589\",\n          \"2024-04-18 04:55:20.436237\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surname\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 496,\n        \"samples\": [\n          \"Ferguson\",\n          \"Mahoney\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_of_birth\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1910-04-18\",\n        \"max\": \"2026-01-12\",\n        \"num_unique_values\": 990,\n        \"samples\": [\n          \"2023-01-13\",\n          \"2003-03-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Tuesday\",\n          \"Friday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"967-303-1354x62975\",\n          \"429-233-9133x679\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"swagner@example.com\",\n          \"joshua52@example.net\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"address\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"3056 Kelly Throughway Apt. 778\\nRogersstad, ID 64716\",\n          \"11622 White Parkway\\nKennethhaven, TX 43731\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 969,\n        \"samples\": [\n          \"New Christinaborough\",\n          \"Andrebury\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"Iowa\",\n          \"New York\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zipcode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"72456\",\n          \"97806\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_address_v2(text):\n",
        "  \"\"\"\n",
        "  Parses an address string into street address, city, state, and zipcode.\n",
        "  This version handles potential variations in the input format.\n",
        "\n",
        "  Args:\n",
        "    text: The address string to parse.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary containing the parsed address components.\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Split the input into lines\n",
        "    lines = text.strip().split('\\n')\n",
        "\n",
        "    # Extract the street address from the first line\n",
        "    street_address = lines[0].strip()\n",
        "\n",
        "    # Extract the city, state, and zipcode from the second line\n",
        "    city_state_zip = lines[1].strip().split(',')\n",
        "    city = city_state_zip[0].strip()\n",
        "    state_zip = city_state_zip[1].strip().split()\n",
        "    state = state_zip[0].strip()\n",
        "    zipcode = state_zip[1].strip()\n",
        "\n",
        "    return {\n",
        "        'street_address': street_address,\n",
        "        'city': city,\n",
        "        'state': state,\n",
        "        'zipcode': zipcode\n",
        "    }\n",
        "\n",
        "  except (IndexError, ValueError):\n",
        "    return None\n",
        "\n",
        "# Example usage\n",
        "text = \"80974 Jeffrey Mountains\\nWest Benjamin, IL 82801\"\n",
        "address = parse_address_v2(text)\n",
        "\n",
        "if address:\n",
        "  print(address)\n",
        "else:\n",
        "  print(\"Could not parse the address.\")"
      ],
      "metadata": {
        "id": "ZraWvumX7WkH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3ee4ee1d-f7b3-49b9-c72d-30b7e094fdbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'street_address': '80974 Jeffrey Mountains', 'city': 'West Benjamin', 'state': 'IL', 'zipcode': '82801'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the parse_address function to each row of the 'address' column\n",
        "demographics[['nu_address', 'nu_city', 'nu_state', 'nu_zipcode']] = demographics['address'].apply(lambda x: pd.Series(parse_address_v2(x)))\n",
        "\n",
        "demographics.head()"
      ],
      "metadata": {
        "id": "dXjBEBKa7Ccq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "ded37fe1-62f3-4047-ce95-9d318125bcad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     binary given_name                   datetime   surname date_of_birth  \\\n",
              "0  binary_1   Danielle 2021-09-18 11:06:40.740474  Gonzalez    1937-05-08   \n",
              "1  binary_1      Ellen 2023-10-26 22:35:16.736140     Allen    1984-08-24   \n",
              "2  binary_2    Matthew 2024-05-01 00:21:23.998693     Flynn    1933-01-01   \n",
              "3  binary_2     Donald 2025-06-21 01:58:05.375285    Vaughn    1924-02-04   \n",
              "4  binary_1      Kathy 2024-07-08 17:00:40.824699  Crawford    1919-04-11   \n",
              "\n",
              "  day_of_week          phone_number                    email  \\\n",
              "0     Tuesday  001-510-723-9903x368    heathbeth@example.net   \n",
              "1      Friday          223-357-6164  scottashlee@example.org   \n",
              "2      Friday      699-323-3336x981    sabrina73@example.org   \n",
              "3   Wednesday          461.337.7790      jason36@example.net   \n",
              "4      Sunday          514-230-6439  cherylhorne@example.org   \n",
              "\n",
              "                                             address              city  \\\n",
              "0                   PSC 2623, Box 0648\\nAPO AE 79751       Murillofort   \n",
              "1    354 Stacey Parks Apt. 728\\nLake Kevin, FL 06933  West Jasminefurt   \n",
              "2                   Unit 0942 Box 1965\\nDPO AE 52063        Orozcoside   \n",
              "3  005 Gonzalez Fords Suite 160\\nMooreborough, WY...       Edwardshire   \n",
              "4             867 John River\\nLake Michael, SD 38874      Kristinville   \n",
              "\n",
              "      state zipcode                    nu_address       nu_city nu_state  \\\n",
              "0      Utah   61629                           NaN           NaN      NaN   \n",
              "1   Indiana   77087     354 Stacey Parks Apt. 728    Lake Kevin       FL   \n",
              "2   Montana   90582                           NaN           NaN      NaN   \n",
              "3  Michigan   99518  005 Gonzalez Fords Suite 160  Mooreborough       WY   \n",
              "4   Vermont   37836                867 John River  Lake Michael       SD   \n",
              "\n",
              "  nu_zipcode  \n",
              "0        NaN  \n",
              "1      06933  \n",
              "2        NaN  \n",
              "3      04241  \n",
              "4      38874  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4094de21-8161-4c87-9fb9-e6fe4d5c8d13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary</th>\n",
              "      <th>given_name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>surname</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>phone_number</th>\n",
              "      <th>email</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>nu_address</th>\n",
              "      <th>nu_city</th>\n",
              "      <th>nu_state</th>\n",
              "      <th>nu_zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Danielle</td>\n",
              "      <td>2021-09-18 11:06:40.740474</td>\n",
              "      <td>Gonzalez</td>\n",
              "      <td>1937-05-08</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>001-510-723-9903x368</td>\n",
              "      <td>heathbeth@example.net</td>\n",
              "      <td>PSC 2623, Box 0648\\nAPO AE 79751</td>\n",
              "      <td>Murillofort</td>\n",
              "      <td>Utah</td>\n",
              "      <td>61629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>2023-10-26 22:35:16.736140</td>\n",
              "      <td>Allen</td>\n",
              "      <td>1984-08-24</td>\n",
              "      <td>Friday</td>\n",
              "      <td>223-357-6164</td>\n",
              "      <td>scottashlee@example.org</td>\n",
              "      <td>354 Stacey Parks Apt. 728\\nLake Kevin, FL 06933</td>\n",
              "      <td>West Jasminefurt</td>\n",
              "      <td>Indiana</td>\n",
              "      <td>77087</td>\n",
              "      <td>354 Stacey Parks Apt. 728</td>\n",
              "      <td>Lake Kevin</td>\n",
              "      <td>FL</td>\n",
              "      <td>06933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Matthew</td>\n",
              "      <td>2024-05-01 00:21:23.998693</td>\n",
              "      <td>Flynn</td>\n",
              "      <td>1933-01-01</td>\n",
              "      <td>Friday</td>\n",
              "      <td>699-323-3336x981</td>\n",
              "      <td>sabrina73@example.org</td>\n",
              "      <td>Unit 0942 Box 1965\\nDPO AE 52063</td>\n",
              "      <td>Orozcoside</td>\n",
              "      <td>Montana</td>\n",
              "      <td>90582</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Donald</td>\n",
              "      <td>2025-06-21 01:58:05.375285</td>\n",
              "      <td>Vaughn</td>\n",
              "      <td>1924-02-04</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>461.337.7790</td>\n",
              "      <td>jason36@example.net</td>\n",
              "      <td>005 Gonzalez Fords Suite 160\\nMooreborough, WY...</td>\n",
              "      <td>Edwardshire</td>\n",
              "      <td>Michigan</td>\n",
              "      <td>99518</td>\n",
              "      <td>005 Gonzalez Fords Suite 160</td>\n",
              "      <td>Mooreborough</td>\n",
              "      <td>WY</td>\n",
              "      <td>04241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Kathy</td>\n",
              "      <td>2024-07-08 17:00:40.824699</td>\n",
              "      <td>Crawford</td>\n",
              "      <td>1919-04-11</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>514-230-6439</td>\n",
              "      <td>cherylhorne@example.org</td>\n",
              "      <td>867 John River\\nLake Michael, SD 38874</td>\n",
              "      <td>Kristinville</td>\n",
              "      <td>Vermont</td>\n",
              "      <td>37836</td>\n",
              "      <td>867 John River</td>\n",
              "      <td>Lake Michael</td>\n",
              "      <td>SD</td>\n",
              "      <td>38874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4094de21-8161-4c87-9fb9-e6fe4d5c8d13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4094de21-8161-4c87-9fb9-e6fe4d5c8d13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4094de21-8161-4c87-9fb9-e6fe4d5c8d13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "demographics",
              "summary": "{\n  \"name\": \"demographics\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"binary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"binary_2\",\n          \"binary_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"given_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 362,\n        \"samples\": [\n          \"Kristen\",\n          \"Nicholas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-01 19:10:50.692840\",\n        \"max\": \"2026-01-31 06:25:39.393294\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2022-06-17 11:39:28.240589\",\n          \"2024-04-18 04:55:20.436237\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surname\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 496,\n        \"samples\": [\n          \"Ferguson\",\n          \"Mahoney\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_of_birth\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1910-04-18\",\n        \"max\": \"2026-01-12\",\n        \"num_unique_values\": 990,\n        \"samples\": [\n          \"2023-01-13\",\n          \"2003-03-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Tuesday\",\n          \"Friday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"967-303-1354x62975\",\n          \"429-233-9133x679\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"swagner@example.com\",\n          \"joshua52@example.net\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"address\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"3056 Kelly Throughway Apt. 778\\nRogersstad, ID 64716\",\n          \"11622 White Parkway\\nKennethhaven, TX 43731\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 969,\n        \"samples\": [\n          \"New Christinaborough\",\n          \"Andrebury\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"Iowa\",\n          \"New York\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zipcode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"72456\",\n          \"97806\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nu_address\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 901,\n        \"samples\": [\n          \"42609 Haynes Tunnel Suite 223\",\n          \"31115 Spears Neck Suite 423\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nu_city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 872,\n        \"samples\": [\n          \"Kristinton\",\n          \"Latoyaborough\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nu_state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 59,\n        \"samples\": [\n          \"FL\",\n          \"ME\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nu_zipcode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 897,\n        \"samples\": [\n          \"05927\",\n          \"90503\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop address, city, state, zipcode and rename nu_ etc.\n",
        "demographics.drop(['address', 'city', 'state', 'zipcode'], axis=1, inplace=True)\n",
        "demographics.rename(columns={'nu_address': 'address', 'nu_city': 'city', 'nu_state': 'state', 'nu_zipcode': 'zipcode'}, inplace=True)\n",
        "demographics.head()"
      ],
      "metadata": {
        "id": "x4Hz9Qpw71M7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "1c6938c3-2305-4808-9f67-541a646e07cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     binary given_name                   datetime   surname date_of_birth  \\\n",
              "0  binary_1   Danielle 2021-09-18 11:06:40.740474  Gonzalez    1937-05-08   \n",
              "1  binary_1      Ellen 2023-10-26 22:35:16.736140     Allen    1984-08-24   \n",
              "2  binary_2    Matthew 2024-05-01 00:21:23.998693     Flynn    1933-01-01   \n",
              "3  binary_2     Donald 2025-06-21 01:58:05.375285    Vaughn    1924-02-04   \n",
              "4  binary_1      Kathy 2024-07-08 17:00:40.824699  Crawford    1919-04-11   \n",
              "\n",
              "  day_of_week          phone_number                    email  \\\n",
              "0     Tuesday  001-510-723-9903x368    heathbeth@example.net   \n",
              "1      Friday          223-357-6164  scottashlee@example.org   \n",
              "2      Friday      699-323-3336x981    sabrina73@example.org   \n",
              "3   Wednesday          461.337.7790      jason36@example.net   \n",
              "4      Sunday          514-230-6439  cherylhorne@example.org   \n",
              "\n",
              "                        address          city state zipcode  \n",
              "0                           NaN           NaN   NaN     NaN  \n",
              "1     354 Stacey Parks Apt. 728    Lake Kevin    FL   06933  \n",
              "2                           NaN           NaN   NaN     NaN  \n",
              "3  005 Gonzalez Fords Suite 160  Mooreborough    WY   04241  \n",
              "4                867 John River  Lake Michael    SD   38874  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02e6086a-3780-4437-a738-ec45e6782f48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary</th>\n",
              "      <th>given_name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>surname</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>phone_number</th>\n",
              "      <th>email</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Danielle</td>\n",
              "      <td>2021-09-18 11:06:40.740474</td>\n",
              "      <td>Gonzalez</td>\n",
              "      <td>1937-05-08</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>001-510-723-9903x368</td>\n",
              "      <td>heathbeth@example.net</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>2023-10-26 22:35:16.736140</td>\n",
              "      <td>Allen</td>\n",
              "      <td>1984-08-24</td>\n",
              "      <td>Friday</td>\n",
              "      <td>223-357-6164</td>\n",
              "      <td>scottashlee@example.org</td>\n",
              "      <td>354 Stacey Parks Apt. 728</td>\n",
              "      <td>Lake Kevin</td>\n",
              "      <td>FL</td>\n",
              "      <td>06933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Matthew</td>\n",
              "      <td>2024-05-01 00:21:23.998693</td>\n",
              "      <td>Flynn</td>\n",
              "      <td>1933-01-01</td>\n",
              "      <td>Friday</td>\n",
              "      <td>699-323-3336x981</td>\n",
              "      <td>sabrina73@example.org</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Donald</td>\n",
              "      <td>2025-06-21 01:58:05.375285</td>\n",
              "      <td>Vaughn</td>\n",
              "      <td>1924-02-04</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>461.337.7790</td>\n",
              "      <td>jason36@example.net</td>\n",
              "      <td>005 Gonzalez Fords Suite 160</td>\n",
              "      <td>Mooreborough</td>\n",
              "      <td>WY</td>\n",
              "      <td>04241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Kathy</td>\n",
              "      <td>2024-07-08 17:00:40.824699</td>\n",
              "      <td>Crawford</td>\n",
              "      <td>1919-04-11</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>514-230-6439</td>\n",
              "      <td>cherylhorne@example.org</td>\n",
              "      <td>867 John River</td>\n",
              "      <td>Lake Michael</td>\n",
              "      <td>SD</td>\n",
              "      <td>38874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02e6086a-3780-4437-a738-ec45e6782f48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02e6086a-3780-4437-a738-ec45e6782f48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02e6086a-3780-4437-a738-ec45e6782f48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "demographics",
              "summary": "{\n  \"name\": \"demographics\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"binary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"binary_2\",\n          \"binary_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"given_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 362,\n        \"samples\": [\n          \"Kristen\",\n          \"Nicholas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-01 19:10:50.692840\",\n        \"max\": \"2026-01-31 06:25:39.393294\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2022-06-17 11:39:28.240589\",\n          \"2024-04-18 04:55:20.436237\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surname\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 496,\n        \"samples\": [\n          \"Ferguson\",\n          \"Mahoney\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_of_birth\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1910-04-18\",\n        \"max\": \"2026-01-12\",\n        \"num_unique_values\": 990,\n        \"samples\": [\n          \"2023-01-13\",\n          \"2003-03-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Tuesday\",\n          \"Friday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"967-303-1354x62975\",\n          \"429-233-9133x679\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"swagner@example.com\",\n          \"joshua52@example.net\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"address\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 901,\n        \"samples\": [\n          \"42609 Haynes Tunnel Suite 223\",\n          \"31115 Spears Neck Suite 423\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 872,\n        \"samples\": [\n          \"Kristinton\",\n          \"Latoyaborough\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 59,\n        \"samples\": [\n          \"FL\",\n          \"ME\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zipcode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 897,\n        \"samples\": [\n          \"05927\",\n          \"90503\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Independent Variable Correlated with Class"
      ],
      "metadata": {
        "id": "4A99Q0IknJCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def generate_feature(df, class_col, coeff, intercept):\n",
        "    \"\"\"\n",
        "    Generates normally distributed feature data for a logistic regression model.\n",
        "\n",
        "    Args:\n",
        "        df: The pandas DataFrame containing the class column.\n",
        "        class_col: The name of the class column (containing 0s and 1s).\n",
        "        coeff: The coefficient for the feature in the logistic regression model.\n",
        "        intercept: The intercept of the logistic regression model.\n",
        "\n",
        "    Returns:\n",
        "        A pandas Series containing the generated feature data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate probabilities based on the class\n",
        "    probs = np.random.rand(len(df))  # Initial random probabilities\n",
        "    probs = np.where(df[class_col] == 1, probs * 0.8 + 0.2, probs * 0.8)  # Adjust for class\n",
        "\n",
        "    # Apply the inverse logit (logit) function\n",
        "    logits = np.log(probs / (1 - probs))\n",
        "\n",
        "    # Calculate the feature values\n",
        "    feature_values = (logits - intercept) / coeff\n",
        "\n",
        "    return pd.Series(feature_values)\n",
        "\n"
      ],
      "metadata": {
        "id": "n3VmXvwBnRr-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Classification"
      ],
      "metadata": {
        "id": "kmOFYI7T_eoP"
      }
    },
    {
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def make_linear_y(row):\n",
        "  model = LogisticRegression()\n",
        "  model.fit(X, y)\n",
        "  coefficients = model.coef_\n",
        "  intercept = model.intercept_\n",
        "  f_of_x = intercept + coefficients[0][0]*row['informative_1'] + coefficients[0][1]*row['informative_2']\n",
        "  # print(f_of_x[0])\n",
        "  return f_of_x[0]\n",
        "\n",
        "# Set n_informative and n_redundant to values that sum to less than n_features\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, random_state=random_state)\n",
        "df = pd.DataFrame(X, columns=['informative_1', 'informative_2'])\n",
        "df = pd.concat([demographics, df], axis=1).reset_index(drop=True)\n",
        "\n",
        "df['target'] = df.apply(make_linear_y, axis=1) # an independent variable\n",
        "df['class'] = y # the dependent variable\n",
        "df['corr_feature_class'] = generate_feature(df, 'class', 0.5, -1)\n",
        "df.head()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1UYr8YXrJkX8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "24950bda-7af7-494b-b22f-8a779b733aea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     binary given_name                   datetime   surname date_of_birth  \\\n",
              "0  binary_1   Danielle 2021-09-18 11:06:40.740474  Gonzalez    1937-05-08   \n",
              "1  binary_1      Ellen 2023-10-26 22:35:16.736140     Allen    1984-08-24   \n",
              "2  binary_2    Matthew 2024-05-01 00:21:23.998693     Flynn    1933-01-01   \n",
              "3  binary_2     Donald 2025-06-21 01:58:05.375285    Vaughn    1924-02-04   \n",
              "4  binary_1      Kathy 2024-07-08 17:00:40.824699  Crawford    1919-04-11   \n",
              "\n",
              "  day_of_week          phone_number                    email  \\\n",
              "0     Tuesday  001-510-723-9903x368    heathbeth@example.net   \n",
              "1      Friday          223-357-6164  scottashlee@example.org   \n",
              "2      Friday      699-323-3336x981    sabrina73@example.org   \n",
              "3   Wednesday          461.337.7790      jason36@example.net   \n",
              "4      Sunday          514-230-6439  cherylhorne@example.org   \n",
              "\n",
              "                        address          city state zipcode  informative_1  \\\n",
              "0                           NaN           NaN   NaN     NaN       0.015782   \n",
              "1     354 Stacey Parks Apt. 728    Lake Kevin    FL   06933      -0.333633   \n",
              "2                           NaN           NaN   NaN     NaN       0.163365   \n",
              "3  005 Gonzalez Fords Suite 160  Mooreborough    WY   04241      -2.300992   \n",
              "4                867 John River  Lake Michael    SD   38874       0.203209   \n",
              "\n",
              "   informative_2    target  class  corr_feature_class  \n",
              "0      -0.650064 -1.808617      0            1.493337  \n",
              "1       1.476125  3.593812      0            1.017254  \n",
              "2      -0.078864 -0.232819      1            3.272118  \n",
              "3      -0.659679 -3.027850      0            3.708797  \n",
              "4      -2.444337 -6.423050      0            2.511652  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04c25995-204b-4f5b-80e8-3e5e6edf7851\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary</th>\n",
              "      <th>given_name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>surname</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>phone_number</th>\n",
              "      <th>email</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>informative_1</th>\n",
              "      <th>informative_2</th>\n",
              "      <th>target</th>\n",
              "      <th>class</th>\n",
              "      <th>corr_feature_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Danielle</td>\n",
              "      <td>2021-09-18 11:06:40.740474</td>\n",
              "      <td>Gonzalez</td>\n",
              "      <td>1937-05-08</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>001-510-723-9903x368</td>\n",
              "      <td>heathbeth@example.net</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.015782</td>\n",
              "      <td>-0.650064</td>\n",
              "      <td>-1.808617</td>\n",
              "      <td>0</td>\n",
              "      <td>1.493337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>2023-10-26 22:35:16.736140</td>\n",
              "      <td>Allen</td>\n",
              "      <td>1984-08-24</td>\n",
              "      <td>Friday</td>\n",
              "      <td>223-357-6164</td>\n",
              "      <td>scottashlee@example.org</td>\n",
              "      <td>354 Stacey Parks Apt. 728</td>\n",
              "      <td>Lake Kevin</td>\n",
              "      <td>FL</td>\n",
              "      <td>06933</td>\n",
              "      <td>-0.333633</td>\n",
              "      <td>1.476125</td>\n",
              "      <td>3.593812</td>\n",
              "      <td>0</td>\n",
              "      <td>1.017254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Matthew</td>\n",
              "      <td>2024-05-01 00:21:23.998693</td>\n",
              "      <td>Flynn</td>\n",
              "      <td>1933-01-01</td>\n",
              "      <td>Friday</td>\n",
              "      <td>699-323-3336x981</td>\n",
              "      <td>sabrina73@example.org</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.163365</td>\n",
              "      <td>-0.078864</td>\n",
              "      <td>-0.232819</td>\n",
              "      <td>1</td>\n",
              "      <td>3.272118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Donald</td>\n",
              "      <td>2025-06-21 01:58:05.375285</td>\n",
              "      <td>Vaughn</td>\n",
              "      <td>1924-02-04</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>461.337.7790</td>\n",
              "      <td>jason36@example.net</td>\n",
              "      <td>005 Gonzalez Fords Suite 160</td>\n",
              "      <td>Mooreborough</td>\n",
              "      <td>WY</td>\n",
              "      <td>04241</td>\n",
              "      <td>-2.300992</td>\n",
              "      <td>-0.659679</td>\n",
              "      <td>-3.027850</td>\n",
              "      <td>0</td>\n",
              "      <td>3.708797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Kathy</td>\n",
              "      <td>2024-07-08 17:00:40.824699</td>\n",
              "      <td>Crawford</td>\n",
              "      <td>1919-04-11</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>514-230-6439</td>\n",
              "      <td>cherylhorne@example.org</td>\n",
              "      <td>867 John River</td>\n",
              "      <td>Lake Michael</td>\n",
              "      <td>SD</td>\n",
              "      <td>38874</td>\n",
              "      <td>0.203209</td>\n",
              "      <td>-2.444337</td>\n",
              "      <td>-6.423050</td>\n",
              "      <td>0</td>\n",
              "      <td>2.511652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04c25995-204b-4f5b-80e8-3e5e6edf7851')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04c25995-204b-4f5b-80e8-3e5e6edf7851 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04c25995-204b-4f5b-80e8-3e5e6edf7851');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"binary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"binary_2\",\n          \"binary_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"given_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 362,\n        \"samples\": [\n          \"Kristen\",\n          \"Nicholas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-01 19:10:50.692840\",\n        \"max\": \"2026-01-31 06:25:39.393294\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2022-06-17 11:39:28.240589\",\n          \"2024-04-18 04:55:20.436237\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surname\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 496,\n        \"samples\": [\n          \"Ferguson\",\n          \"Mahoney\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_of_birth\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1910-04-18\",\n        \"max\": \"2026-01-12\",\n        \"num_unique_values\": 990,\n        \"samples\": [\n          \"2023-01-13\",\n          \"2003-03-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Tuesday\",\n          \"Friday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"967-303-1354x62975\",\n          \"429-233-9133x679\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"swagner@example.com\",\n          \"joshua52@example.net\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"address\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 901,\n        \"samples\": [\n          \"42609 Haynes Tunnel Suite 223\",\n          \"31115 Spears Neck Suite 423\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 872,\n        \"samples\": [\n          \"Kristinton\",\n          \"Latoyaborough\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 59,\n        \"samples\": [\n          \"FL\",\n          \"ME\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zipcode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 897,\n        \"samples\": [\n          \"05927\",\n          \"90503\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"informative_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3907771391630195,\n        \"min\": -4.281092268690118,\n        \"max\": 3.1152885521196048,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.014373834732724688,\n          -0.18547886289771276\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"informative_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3837540936144912,\n        \"min\": -3.8978242632228057,\n        \"max\": 3.8120727350007093,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.5878673091274096,\n          -1.8563019863764185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.615522894282748,\n        \"min\": -8.943425038058257,\n        \"max\": 11.10613214076194,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          1.4409615581594761,\n          -5.079428122986213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"corr_feature_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1024792894739113,\n        \"min\": -12.790294076881082,\n        \"max\": 16.821439579966054,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          2.9625892523203663,\n          2.1779324522585797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automation Functions\n",
        "\n",
        "1. gen_null(series, perc)\n",
        "2. gen_quasi_constants(primary_label, variation_percentage=.2, replace=False)\n",
        "3. gen_normal_data(mu=0, std=1, size=len(df))\n",
        "4. gen_uniform_data(size=len(df))\n",
        "5. gen_multivariate_normal_data(mean=[0, 0], cov=[[1, 0], [0, 1]], size=len(df))\n",
        "6. gen_correlated_normal_series(original_series, target_correlation, size=len(df))\n",
        "7. gen_correlated_uniform_series(original_series, correlation_coefficient=0, size=len(df))\n",
        "8. gen_outliers(mean=0, std_dev=1, size=len(df), outlier_percentage=0.1, outlier_magnitude=3)\n",
        "9. gen_standard_scaling(mean=50, std_dev=10, size=len(df), scale_factor=1000)\n",
        "10. gen_minmax_scaling(mean=50, std_dev=10, size=len(df), range_factor=10)\n",
        "11. random_choice_data(choices, size)"
      ],
      "metadata": {
        "id": "FlnsQrSN8FLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# functions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "\n",
        "def gen_null(series, perc):\n",
        "  \"\"\"\n",
        "  Introduces null values (np.nan) into a list based on a specified percentage.\n",
        "\n",
        "  Args:\n",
        "      var: The variable to modify.\n",
        "      perc: The percentage of values to replace with nulls (0-100).\n",
        "\n",
        "  Returns:\n",
        "      The modified variable with null.\n",
        "  \"\"\"\n",
        "  var = series.copy()\n",
        "  num_nulls = int(len(var) * (perc / 100))\n",
        "  indices_to_replace = np.random.choice(len(var), num_nulls, replace=False)\n",
        "\n",
        "  for idx in indices_to_replace:\n",
        "      var[idx] = np.nan\n",
        "\n",
        "  return var\n",
        "\n",
        "def gen_quasi_constants(primary_label, variation_percentage=.2, size=len(df)):\n",
        "  \"\"\"\n",
        "  Generates quasi-constant labels for a Series, with a small percentage of variation.\n",
        "\n",
        "  Args:\n",
        "      primary_label: The main label to use for most values.\n",
        "      variation_percentage: The percentage of labels to vary (0-100).\n",
        "\n",
        "  Returns:\n",
        "      A new Series containing the quasi-constant labels.\n",
        "  \"\"\"\n",
        "\n",
        "  series = pd.Series(np.full(size, primary_label))\n",
        "  num_variations = int(size * (variation_percentage / 100))\n",
        "  variation_indices = np.random.choice(series.index, num_variations, replace=False)\n",
        "  primary_label = primary_label + '_0'\n",
        "  variation1 = primary_label + '_1'\n",
        "  variation2 = primary_label + '_2'\n",
        "\n",
        "  labels = pd.Series([primary_label] * len(series), index=series.index)\n",
        "  labels.loc[variation_indices] = np.random.choice([variation1, variation2], size=num_variations)  # Adjust variations as needed\n",
        "\n",
        "  return labels\n",
        "\n",
        "def gen_normal_data(mu=0, std=1, size=len(df)):\n",
        "  \"\"\"\n",
        "  Generates a normal dataset given the mean and standard deviation\n",
        "\n",
        "  Args:\n",
        "        mu: The mean of the normal distribution.\n",
        "        std: The standard deviation of the normal distribution.\n",
        "        size: The number of data points to generate.\n",
        "\n",
        "  Returns:\n",
        "        A normally distributed series.\n",
        "  \"\"\"\n",
        "  return np.random.normal(mu, std, size)\n",
        "\n",
        "def gen_uniform_data(size=len(df)):\n",
        "  \"\"\"\n",
        "  Generates a uniform dataset\n",
        "\n",
        "  Args:\n",
        "        size: The number of data points to generate.\n",
        "\n",
        "  Returns:\n",
        "        A uniform distributed series.\n",
        "  \"\"\"\n",
        "  return np.random.uniform(size=size)\n",
        "\n",
        "def gen_multivariate_normal_data(mean=[0, 0], cov=[[1, 0], [0, 1]], size=len(df)):\n",
        "  \"\"\"\n",
        "  Generates two datasets with a multivariate normal distribution given the mean and covariance matrix\n",
        "\n",
        "  Args:\n",
        "        mean: The mean of each of the datasets.\n",
        "        cov: The covariance matrix of the datasets.\n",
        "        size: The number of data points to generate.\n",
        "\n",
        "  Returns:\n",
        "        Two correlated series.\n",
        "  \"\"\"\n",
        "  ds1, ds2 = np.random.multivariate_normal(mean, cov, size, tol=1e-6).T # ds = dataset\n",
        "  return ds1, ds2\n",
        "\n",
        "def gen_correlated_normal_series(original_series, target_correlation, size=len(df)):\n",
        "  \"\"\"\n",
        "  Generates a correlated series based on a given series.\n",
        "\n",
        "  This function takes an original series as input and generates a new series\n",
        "  that is correlated with the original series. The correlation between the\n",
        "  original and generated series is approximately equal to the specified\n",
        "  target correlation.\n",
        "\n",
        "  The generated series is created by linearly transforming the original series\n",
        "  and adding Gaussian noise with an adjusted standard deviation to achieve the\n",
        "  desired correlation.\n",
        "\n",
        "  Args:\n",
        "      original_series (numpy.ndarray): The original series.\n",
        "      target_correlation (float): The desired Pearson correlation coefficient\n",
        "          between the original and generated series.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: The generated correlated series.\n",
        "  \"\"\"\n",
        "  return np.mean(original_series) + target_correlation * (original_series - np.mean(original_series)) \\\n",
        "  +  np.random.normal(0, np.sqrt(1 - target_correlation**2) * np.std(original_series), len(original_series))\n",
        "  \"\"\"\n",
        "  Explanation\n",
        "\n",
        "  This one-liner leverages the properties of linear transformations and normal distributions to generate a correlated series.\n",
        "\n",
        "  It first centers the original_series by subtracting its mean.\n",
        "  It then scales this centered series by the target_correlation.\n",
        "  Finally, it adds Gaussian noise with a standard deviation adjusted to ensure the overall correlation matches the target_correlation.\n",
        "  \"\"\"\n",
        "\n",
        "def gen_correlated_uniform_series(original_series, correlation_coefficient=0, size=len(df)):\n",
        "  \"\"\"\n",
        "  Work in progress\n",
        "\n",
        "  Generates a new series correlated with the given series based on the specified correlation coefficient,\n",
        "  using rank correlation to ensure the generated series follows a uniform distribution.\n",
        "\n",
        "  Args:\n",
        "      original_series (numpy.ndarray or list): The original series.\n",
        "      correlation_coefficient (float): The desired correlation coefficient between the original and generated series.\n",
        "      size: The number of data points to generate.\n",
        "\n",
        "  Returns:\n",
        "      The generated correlated series with a uniform distribution.\n",
        "  \"\"\"\n",
        "  z_scores = (original_series - np.mean(original_series)) / np.std(original_series)\n",
        "  correlation_coefficient=.7\n",
        "  return norm.cdf(correlation_coefficient * norm.ppf(np.random.uniform(size=size)) + np.sqrt(1 - correlation_coefficient**2) * z_scores)\n",
        "\n",
        "def pearson_r_func(x, y, y_mean, y_std, desired_r):\n",
        "    x_mean = np.mean(x)\n",
        "    x_std = np.std(x)\n",
        "    numerator = np.sum((x - x_mean) * (y - y_mean))\n",
        "    denominator = x_std * y_std * len(x)\n",
        "    calculated_r = numerator / denominator\n",
        "    return (calculated_r - desired_r)**2  # Minimize the squared difference\n",
        "\n",
        "def minimize_r(original_series, target_correlation, size=len(df)):\n",
        "    y = original_series\n",
        "    y_mean = np.mean(y)\n",
        "    y_std = np.std(y)\n",
        "    desired_r = target_correlation\n",
        "\n",
        "    # Initial guess for x values\n",
        "    x0 = np.random.uniform(size=len(original_series))\n",
        "\n",
        "    # Solve for x\n",
        "    result = minimize(pearson_r_func, x0, args=(y, y_mean, y_std, desired_r))\n",
        "\n",
        "    if result.success:\n",
        "        x_solution = result.x\n",
        "        # print(\"Solution for x:\", x_solution)\n",
        "        return x_solution\n",
        "    else:\n",
        "        print(\"Optimization failed.\")\n",
        "\n",
        "def gen_outliers(mean=0, std_dev=1, size=len(df), outlier_percentage=0.1, outlier_magnitude=3):\n",
        "    \"\"\"\n",
        "    Generates a normal distribution with outliers.\n",
        "\n",
        "    Args:\n",
        "        mean (float): The mean of the normal distribution.\n",
        "        std_dev (float): The standard deviation of the normal distribution.\n",
        "        size (int): The number of samples to generate.\n",
        "        outlier_percentage (float): The percentage of outliers to introduce (between 0 and 1).\n",
        "        outlier_magnitude (float): The magnitude by which outliers deviate from the mean.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The generated data with outliers.\n",
        "    \"\"\"\n",
        "    data = np.random.normal(mean, std_dev, size)\n",
        "    num_outliers = int(size * outlier_percentage)\n",
        "    outlier_indices = np.random.choice(size, num_outliers, replace=False)\n",
        "    for index in outlier_indices:\n",
        "        if np.random.rand() < 0.5:\n",
        "            data[index] += outlier_magnitude\n",
        "        else:\n",
        "            data[index] -= outlier_magnitude\n",
        "\n",
        "    return data\n",
        "\n",
        "def gen_standard_scaling(mean=50, std_dev=10, size=len(df), scale_factor=1000):\n",
        "  \"\"\"\n",
        "  Generates data with a specified mean and standard deviation, then scales it by a factor to create a distribution needing scaling.\n",
        "\n",
        "  Args:\n",
        "      mean (float): The mean of the original distribution.\n",
        "      std_dev (float): The standard deviation of the original distribution.\n",
        "      size (int): The number of samples to generate.\n",
        "      scale_factor (float): The factor by which to scale the original distribution.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: The generated data needing scaling.\n",
        "  \"\"\"\n",
        "  original_data = np.random.normal(mean, std_dev, size)\n",
        "  return original_data * scale_factor\n",
        "\n",
        "def gen_minmax_scaling(mean=50, std_dev=10, size=len(df), range_factor=10):\n",
        "  \"\"\"\n",
        "  Generates data with a specified mean and standard deviation, then scales and shifts it to create a distribution needing MinMax scaling.\n",
        "\n",
        "  Args:\n",
        "      mean (float): The mean of the original distribution.\n",
        "      std_dev (float): The standard deviation of the original distribution.\n",
        "      size (int): The number of samples to generate.\n",
        "      range_factor (float): The factor to expand the range of the original distribution.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: The generated data needing scaling.\n",
        "  \"\"\"\n",
        "\n",
        "  # Generate the original data\n",
        "  original_data = np.random.normal(mean, std_dev, size)\n",
        "\n",
        "  # Expand the range of the data\n",
        "  min_val = np.min(original_data)\n",
        "  max_val = np.max(original_data)\n",
        "  return (original_data - min_val) * range_factor + min_val\n",
        "\n",
        "def random_choice_data(choices, size):\n",
        "  \"\"\"\n",
        "  Generates a new series correlated with the given series based on the specified correlation coefficient,\n",
        "  using rank correlation to ensure the generated series follows a uniform distribution.\n",
        "\n",
        "  Args:\n",
        "      original_series (numpy.ndarray or list): The original series.\n",
        "      correlation_coefficient (float): The desired correlation coefficient between the original and generated series.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: The generated correlated series with a uniform distribution.\n",
        "  \"\"\"\n",
        "  return np.random.choice(choices, size=size)\n"
      ],
      "metadata": {
        "id": "JWOa9CmWQQ3-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical variables with little correlation to DV\n",
        "df['random choice 2'] = random_choice_data(['Rand Choice 1', 'Rand Choice 2'], size=len(df))\n",
        "df['random choice 4'] = random_choice_data(['North', 'South', 'East', 'West'], size=len(df))\n",
        "df['random choice 7'] = random_choice_data(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], size=len(df))\n",
        "\n",
        "# categorical random choices with random # of labels\n",
        "num_labels = np.random.randint(3, 5)\n",
        "df[f'random label num {num_labels}'] = random_choice_data([f'label num lo {i}' for i in range(1, num_labels + 1)], size=len(df))\n",
        "\n",
        "num_labels = np.random.randint(10, 15)\n",
        "df[f'random label num {num_labels}'] = random_choice_data([f'label num hi {i}' for i in range(1, num_labels + 1)], size=len(df))"
      ],
      "metadata": {
        "id": "OwAolbPsxTxS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical variables correlated with target\n",
        "df['pd qcut1'] = pd.qcut(df['target'], 2, labels=['Low', 'High']) # bi label\n",
        "df['pd qcut2'] = pd.qcut(df['target'], 4, labels=['Q1', 'Q2', 'Q3', 'Q4']) # 4 labels\n",
        "\n",
        "quantiles = [0, 0.1, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "df['pd qcut3'] = pd.qcut(df['target'], quantiles, labels=['G1', 'G2', 'G3', 'G4', 'G5', 'G6']) # 6 labels"
      ],
      "metadata": {
        "id": "oiR1SK-QR7Rn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate four numerical normally distributed continuous features that have a correlation greater than absolute value of .5 with each other\n",
        "# gen_multivariate_normal_data(mean=[0, 0], cov=[[1, 0], [0, 1]], size=len(df))\n",
        "df['multicollinearity 1'], df['multicollinearity 2'] = gen_multivariate_normal_data(mean=[0, 0], cov=[[1, .7], [.7, 1]], size=len(df))\n",
        "df['multicollinearity 3'], df['multicollinearity 4'] = gen_multivariate_normal_data(mean=[0, 0], cov=[[1, .9], [.9, 1]], size=len(df))"
      ],
      "metadata": {
        "id": "Q6QTLoR2uPkF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate two normally distributed features that are correlated with the target\n",
        "# gen_correlated_normal_series(original_series, target_correlation, size=len(df))\n",
        "df['correlated w target 1'] = gen_correlated_normal_series(df['target'], target_correlation=.5)\n",
        "df['correlated w target 2'] = gen_correlated_normal_series(df['target'], target_correlation=.7)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "EyUCReGZlSSl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "efd164c4-c78b-4993-db9a-027bc2c2288a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 31 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   binary                 1000 non-null   object        \n",
            " 1   given_name             1000 non-null   object        \n",
            " 2   datetime               1000 non-null   datetime64[ns]\n",
            " 3   surname                1000 non-null   object        \n",
            " 4   date_of_birth          1000 non-null   object        \n",
            " 5   day_of_week            1000 non-null   object        \n",
            " 6   phone_number           1000 non-null   object        \n",
            " 7   email                  1000 non-null   object        \n",
            " 8   address                901 non-null    object        \n",
            " 9   city                   901 non-null    object        \n",
            " 10  state                  901 non-null    object        \n",
            " 11  zipcode                901 non-null    object        \n",
            " 12  informative_1          1000 non-null   float64       \n",
            " 13  informative_2          1000 non-null   float64       \n",
            " 14  target                 1000 non-null   float64       \n",
            " 15  class                  1000 non-null   int64         \n",
            " 16  corr_feature_class     1000 non-null   float64       \n",
            " 17  random choice 2        1000 non-null   object        \n",
            " 18  random choice 4        1000 non-null   object        \n",
            " 19  random choice 7        1000 non-null   object        \n",
            " 20  random label num 4     1000 non-null   object        \n",
            " 21  random label num 14    1000 non-null   object        \n",
            " 22  pd qcut1               1000 non-null   category      \n",
            " 23  pd qcut2               1000 non-null   category      \n",
            " 24  pd qcut3               1000 non-null   category      \n",
            " 25  multicollinearity 1    1000 non-null   float64       \n",
            " 26  multicollinearity 2    1000 non-null   float64       \n",
            " 27  multicollinearity 3    1000 non-null   float64       \n",
            " 28  multicollinearity 4    1000 non-null   float64       \n",
            " 29  correlated w target 1  1000 non-null   float64       \n",
            " 30  correlated w target 2  1000 non-null   float64       \n",
            "dtypes: category(3), datetime64[ns](1), float64(10), int64(1), object(16)\n",
            "memory usage: 222.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate two uniformly distributed features that are correlated with the target\n",
        "# gen_correlated_uniform_series(original_series, correlation_coefficient=0, size=len(df))\n",
        "df['uniform corr 1'] = gen_correlated_uniform_series(df['target'])\n",
        "df['uniform corr 2'] = gen_correlated_uniform_series(df['target'])\n",
        "\n",
        "print(df[['uniform corr 1', 'uniform corr 2', 'target']].corr())\n",
        "df[['uniform corr 1', 'uniform corr 2']].hist();"
      ],
      "metadata": {
        "id": "nEQxB18Juh8M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "2c6fc842-e2f8-41bd-fcc7-c9632469f256"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                uniform corr 1  uniform corr 2    target\n",
            "uniform corr 1        1.000000        0.484524  0.706445\n",
            "uniform corr 2        0.484524        1.000000  0.696609\n",
            "target                0.706445        0.696609  1.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create two features that are duplicates of other features\n",
        "df['duplicate_1'] = df['informative_1']\n",
        "df['duplicate_2'] = df['informative_2']"
      ],
      "metadata": {
        "id": "Vx1_vq2FIxan"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create two numerical features with outliers\n",
        "df['outliers 1'] = gen_outliers(mean=0, std_dev=1, size=len(df), outlier_percentage=0.1, outlier_magnitude=3)\n",
        "df['outliers 2'] = gen_outliers(mean=3, std_dev=2, size=len(df), outlier_percentage=0.2, outlier_magnitude=2)"
      ],
      "metadata": {
        "id": "wJGVW0OMJKCA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a numerical feature that needs standard scaling\n",
        "df['standard scaling'] = gen_standard_scaling()"
      ],
      "metadata": {
        "id": "oNXKVbukJUX6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a numerical feature that needs min max scaling\n",
        "df['min max scaling'] = gen_minmax_scaling()"
      ],
      "metadata": {
        "id": "YffL2FIjJZBe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate null values\n",
        "for col in df.drop(['class', 'informative_1', 'informative_2', 'target', 'duplicate_1', 'duplicate_2'], axis=1).columns:\n",
        "    df[col] = gen_null(df[col], np.random.choice([0, 5, 10, 20, 30, 50], size=1).item())"
      ],
      "metadata": {
        "id": "BSB0O7puJmJb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create two features that have constant values\n",
        "df['constant_1'] = 'constant_value'\n",
        "df['constant_2'] = 'constant_value'"
      ],
      "metadata": {
        "id": "2sfkZqmYIjDF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create two features with semi constant values\n",
        "df['semi_constant_1'] = gen_quasi_constants('q_const', variation_percentage = 1)\n",
        "df['semi_constant_2'] = gen_quasi_constants('q_const', variation_percentage = 1)"
      ],
      "metadata": {
        "id": "gWSpRTvfIp1c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())  # check your work"
      ],
      "metadata": {
        "id": "nQ8w6T9WYLf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0e6ba5e6-4d2d-486c-81f4-0988d821e0c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 43 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   binary                 1000 non-null   object        \n",
            " 1   given_name             900 non-null    object        \n",
            " 2   datetime               1000 non-null   datetime64[ns]\n",
            " 3   surname                500 non-null    object        \n",
            " 4   date_of_birth          500 non-null    object        \n",
            " 5   day_of_week            900 non-null    object        \n",
            " 6   phone_number           700 non-null    object        \n",
            " 7   email                  700 non-null    object        \n",
            " 8   address                856 non-null    object        \n",
            " 9   city                   450 non-null    object        \n",
            " 10  state                  811 non-null    object        \n",
            " 11  zipcode                623 non-null    object        \n",
            " 12  informative_1          1000 non-null   float64       \n",
            " 13  informative_2          1000 non-null   float64       \n",
            " 14  target                 1000 non-null   float64       \n",
            " 15  class                  1000 non-null   int64         \n",
            " 16  corr_feature_class     950 non-null    float64       \n",
            " 17  random choice 2        950 non-null    object        \n",
            " 18  random choice 4        700 non-null    object        \n",
            " 19  random choice 7        1000 non-null   object        \n",
            " 20  random label num 4     500 non-null    object        \n",
            " 21  random label num 14    950 non-null    object        \n",
            " 22  pd qcut1               1000 non-null   category      \n",
            " 23  pd qcut2               900 non-null    category      \n",
            " 24  pd qcut3               800 non-null    category      \n",
            " 25  multicollinearity 1    800 non-null    float64       \n",
            " 26  multicollinearity 2    800 non-null    float64       \n",
            " 27  multicollinearity 3    900 non-null    float64       \n",
            " 28  multicollinearity 4    950 non-null    float64       \n",
            " 29  correlated w target 1  900 non-null    float64       \n",
            " 30  correlated w target 2  500 non-null    float64       \n",
            " 31  uniform corr 1         900 non-null    float64       \n",
            " 32  uniform corr 2         950 non-null    float64       \n",
            " 33  duplicate_1            1000 non-null   float64       \n",
            " 34  duplicate_2            1000 non-null   float64       \n",
            " 35  outliers 1             500 non-null    float64       \n",
            " 36  outliers 2             950 non-null    float64       \n",
            " 37  standard scaling       950 non-null    float64       \n",
            " 38  min max scaling        950 non-null    float64       \n",
            " 39  constant_1             1000 non-null   object        \n",
            " 40  constant_2             1000 non-null   object        \n",
            " 41  semi_constant_1        1000 non-null   object        \n",
            " 42  semi_constant_2        1000 non-null   object        \n",
            "dtypes: category(3), datetime64[ns](1), float64(18), int64(1), object(20)\n",
            "memory usage: 316.1+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add duplicates\n",
        "dupes = df.loc[0:9]\n",
        "df = pd.concat([df, dupes], axis=0)\n",
        "\n",
        "# shuffle all columns\n",
        "# df = df.sample(frac=1).reset_index(drop=True)\n",
        "# df = df.sample(frac=1, axis=1)\n",
        "\n",
        "# shuffle selected columns\n",
        "demographic_columns = demographics.columns\n",
        "remaining_columns = [col for col in df.columns if col not in demographic_columns]\n",
        "# print(remaining_columns)\n",
        "np.random.shuffle(remaining_columns)\n",
        "\n",
        "# Reassemble the DataFrame with the shuffled columns\n",
        "df = df[list(demographic_columns) + list(remaining_columns)]\n",
        "\n",
        "# move target to the end of the list\n",
        "class_var = 'class'\n",
        "df = df[df.drop('class', axis=1).columns.tolist() + [class_var]]\n",
        "\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CiFb0YwCXupw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1401
        },
        "outputId": "dc51d9b3-d660-4493-a8c0-7cd347720fef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1010, 43)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1010 entries, 0 to 9\n",
            "Data columns (total 43 columns):\n",
            " #   Column                 Non-Null Count  Dtype         \n",
            "---  ------                 --------------  -----         \n",
            " 0   binary                 1010 non-null   object        \n",
            " 1   given_name             909 non-null    object        \n",
            " 2   datetime               1010 non-null   datetime64[ns]\n",
            " 3   surname                503 non-null    object        \n",
            " 4   date_of_birth          503 non-null    object        \n",
            " 5   day_of_week            909 non-null    object        \n",
            " 6   phone_number           707 non-null    object        \n",
            " 7   email                  705 non-null    object        \n",
            " 8   address                862 non-null    object        \n",
            " 9   city                   454 non-null    object        \n",
            " 10  state                  816 non-null    object        \n",
            " 11  zipcode                626 non-null    object        \n",
            " 12  duplicate_2            1010 non-null   float64       \n",
            " 13  multicollinearity 1    807 non-null    float64       \n",
            " 14  min max scaling        959 non-null    float64       \n",
            " 15  pd qcut1               1010 non-null   category      \n",
            " 16  uniform corr 2         960 non-null    float64       \n",
            " 17  constant_1             1010 non-null   object        \n",
            " 18  pd qcut2               910 non-null    category      \n",
            " 19  pd qcut3               809 non-null    category      \n",
            " 20  multicollinearity 2    809 non-null    float64       \n",
            " 21  duplicate_1            1010 non-null   float64       \n",
            " 22  random choice 4        706 non-null    object        \n",
            " 23  semi_constant_2        1010 non-null   object        \n",
            " 24  corr_feature_class     960 non-null    float64       \n",
            " 25  target                 1010 non-null   float64       \n",
            " 26  informative_1          1010 non-null   float64       \n",
            " 27  outliers 1             503 non-null    float64       \n",
            " 28  correlated w target 2  506 non-null    float64       \n",
            " 29  random choice 7        1010 non-null   object        \n",
            " 30  semi_constant_1        1010 non-null   object        \n",
            " 31  multicollinearity 4    959 non-null    float64       \n",
            " 32  outliers 2             959 non-null    float64       \n",
            " 33  random choice 2        959 non-null    object        \n",
            " 34  standard scaling       960 non-null    float64       \n",
            " 35  random label num 4     505 non-null    object        \n",
            " 36  uniform corr 1         908 non-null    float64       \n",
            " 37  informative_2          1010 non-null   float64       \n",
            " 38  random label num 14    959 non-null    object        \n",
            " 39  correlated w target 1  910 non-null    float64       \n",
            " 40  multicollinearity 3    909 non-null    float64       \n",
            " 41  constant_2             1010 non-null   object        \n",
            " 42  class                  1010 non-null   int64         \n",
            "dtypes: category(3), datetime64[ns](1), float64(18), int64(1), object(20)\n",
            "memory usage: 327.0+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     binary given_name                   datetime surname date_of_birth  \\\n",
              "0  binary_1   Danielle 2021-09-18 11:06:40.740474     NaN           NaN   \n",
              "1  binary_1        NaN 2023-10-26 22:35:16.736140     NaN    1984-08-24   \n",
              "2  binary_2    Matthew 2024-05-01 00:21:23.998693   Flynn           NaN   \n",
              "3  binary_2     Donald 2025-06-21 01:58:05.375285     NaN           NaN   \n",
              "4  binary_1      Kathy 2024-07-08 17:00:40.824699     NaN           NaN   \n",
              "\n",
              "  day_of_week          phone_number                email  \\\n",
              "0     Tuesday  001-510-723-9903x368                  NaN   \n",
              "1      Friday          223-357-6164                  NaN   \n",
              "2      Friday      699-323-3336x981                  NaN   \n",
              "3   Wednesday                   NaN  jason36@example.net   \n",
              "4      Sunday                   NaN                  NaN   \n",
              "\n",
              "                        address          city  ... random choice 2  \\\n",
              "0                           NaN           NaN  ...   Rand Choice 2   \n",
              "1     354 Stacey Parks Apt. 728    Lake Kevin  ...   Rand Choice 2   \n",
              "2                           NaN           NaN  ...   Rand Choice 2   \n",
              "3  005 Gonzalez Fords Suite 160  Mooreborough  ...             NaN   \n",
              "4                867 John River  Lake Michael  ...   Rand Choice 1   \n",
              "\n",
              "  standard scaling  random label num 4  uniform corr 1  informative_2  \\\n",
              "0     44483.698814                 NaN        0.354397      -0.650064   \n",
              "1     62464.231602      label num lo 1        0.923138       1.476125   \n",
              "2     54802.036116      label num lo 2             NaN      -0.078864   \n",
              "3     55781.015440                 NaN        0.744835      -0.659679   \n",
              "4     70455.687013      label num lo 1        0.030535      -2.444337   \n",
              "\n",
              "  random label num 14  correlated w target 1 multicollinearity 3  \\\n",
              "0      label num hi 2               1.851500            0.819735   \n",
              "1                 NaN              -4.608061            0.696774   \n",
              "2     label num hi 12               0.511836                 NaN   \n",
              "3      label num hi 6               3.389679           -0.296270   \n",
              "4      label num hi 2              -2.472265            0.221505   \n",
              "\n",
              "       constant_2 class  \n",
              "0  constant_value     0  \n",
              "1  constant_value     0  \n",
              "2  constant_value     1  \n",
              "3  constant_value     0  \n",
              "4  constant_value     0  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03de791f-da46-46b1-a208-81598bf65055\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary</th>\n",
              "      <th>given_name</th>\n",
              "      <th>datetime</th>\n",
              "      <th>surname</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>phone_number</th>\n",
              "      <th>email</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>...</th>\n",
              "      <th>random choice 2</th>\n",
              "      <th>standard scaling</th>\n",
              "      <th>random label num 4</th>\n",
              "      <th>uniform corr 1</th>\n",
              "      <th>informative_2</th>\n",
              "      <th>random label num 14</th>\n",
              "      <th>correlated w target 1</th>\n",
              "      <th>multicollinearity 3</th>\n",
              "      <th>constant_2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Danielle</td>\n",
              "      <td>2021-09-18 11:06:40.740474</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>001-510-723-9903x368</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Rand Choice 2</td>\n",
              "      <td>44483.698814</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.354397</td>\n",
              "      <td>-0.650064</td>\n",
              "      <td>label num hi 2</td>\n",
              "      <td>1.851500</td>\n",
              "      <td>0.819735</td>\n",
              "      <td>constant_value</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-10-26 22:35:16.736140</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1984-08-24</td>\n",
              "      <td>Friday</td>\n",
              "      <td>223-357-6164</td>\n",
              "      <td>NaN</td>\n",
              "      <td>354 Stacey Parks Apt. 728</td>\n",
              "      <td>Lake Kevin</td>\n",
              "      <td>...</td>\n",
              "      <td>Rand Choice 2</td>\n",
              "      <td>62464.231602</td>\n",
              "      <td>label num lo 1</td>\n",
              "      <td>0.923138</td>\n",
              "      <td>1.476125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-4.608061</td>\n",
              "      <td>0.696774</td>\n",
              "      <td>constant_value</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Matthew</td>\n",
              "      <td>2024-05-01 00:21:23.998693</td>\n",
              "      <td>Flynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Friday</td>\n",
              "      <td>699-323-3336x981</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Rand Choice 2</td>\n",
              "      <td>54802.036116</td>\n",
              "      <td>label num lo 2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.078864</td>\n",
              "      <td>label num hi 12</td>\n",
              "      <td>0.511836</td>\n",
              "      <td>NaN</td>\n",
              "      <td>constant_value</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>binary_2</td>\n",
              "      <td>Donald</td>\n",
              "      <td>2025-06-21 01:58:05.375285</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jason36@example.net</td>\n",
              "      <td>005 Gonzalez Fords Suite 160</td>\n",
              "      <td>Mooreborough</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55781.015440</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.744835</td>\n",
              "      <td>-0.659679</td>\n",
              "      <td>label num hi 6</td>\n",
              "      <td>3.389679</td>\n",
              "      <td>-0.296270</td>\n",
              "      <td>constant_value</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>binary_1</td>\n",
              "      <td>Kathy</td>\n",
              "      <td>2024-07-08 17:00:40.824699</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>867 John River</td>\n",
              "      <td>Lake Michael</td>\n",
              "      <td>...</td>\n",
              "      <td>Rand Choice 1</td>\n",
              "      <td>70455.687013</td>\n",
              "      <td>label num lo 1</td>\n",
              "      <td>0.030535</td>\n",
              "      <td>-2.444337</td>\n",
              "      <td>label num hi 2</td>\n",
              "      <td>-2.472265</td>\n",
              "      <td>0.221505</td>\n",
              "      <td>constant_value</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03de791f-da46-46b1-a208-81598bf65055')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-03de791f-da46-46b1-a208-81598bf65055 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-03de791f-da46-46b1-a208-81598bf65055');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('simulated_data.csv', index=False)"
      ],
      "metadata": {
        "id": "Legtg7PmvNor"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive\n",
        "\n",
        "This is optional, if you want to save your simulated_data.csv to your Google Drive."
      ],
      "metadata": {
        "id": "g_XqWl1r3w5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Mount Drive\n",
        "# import shutil\n",
        "\n",
        "# # Source file path (within your Drive)\n",
        "# source_file = '/content/filename'\n",
        "\n",
        "# # Destination path (root of your Drive)\n",
        "# destination_path = '/content/drive/MyDrive/filepath/filename'\n",
        "\n",
        "# # Copy the file\n",
        "# shutil.copy(source_file, destination_path)"
      ],
      "metadata": {
        "id": "aUUjViiUOEcb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep Process"
      ],
      "metadata": {
        "id": "K3nv3YmhSHkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "nWWZXj_t7wkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the simulated data\n",
        "# print the shape\n",
        "# print the info\n",
        "# print the head\n"
      ],
      "metadata": {
        "id": "GER6wToI7wkI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Types and Characteristics of Data\n",
        "\n",
        "**Numerical Data**\n",
        "\n",
        "This refers to columns with a numerical data type, typically integers (`int64`) or floating-point numbers (`float64`). These data represent quantities and are used for mathematical operations.\n",
        "\n",
        "* **Characteristics**:\n",
        "    * **Continuous**: Can take any value within a given range (e.g., height, temperature, price).\n",
        "    * **Discrete**: Can only take specific, distinct values (e.g., number of children, counts).\n",
        "    * **Order**: The values have a meaningful order and can be compared (e.g., 10 is greater than 5).\n",
        "    * **Mathematical Operations**: Can be used for calculations like mean, standard deviation, and regression analysis.\n",
        "\n",
        "**Object/String Data**\n",
        "\n",
        "This refers to columns with an `object` data type, which in pandas often means they contain text or strings. These are non-numeric and don't have inherent mathematical properties.\n",
        "\n",
        "* **Characteristics**:\n",
        "    * **Nominal**: Categories without a meaningful order (e.g., colors like \"red,\" \"blue,\" \"green\").\n",
        "    * **Textual**: Contains free-form text, which might require natural language processing (NLP) techniques for analysis.\n",
        "    * **High Cardinality**: Often contain a large number of unique values, making them difficult to use directly in many machine learning models without preprocessing.\n",
        "\n",
        "**Categorical Data**\n",
        "\n",
        "This refers to columns with a `category` data type. A `category` type is a pandas-specific data type that is more memory-efficient than `object` for columns with a limited number of unique values.\n",
        "\n",
        "* **Characteristics**:\n",
        "    * **Ordinal**: Categories with a meaningful order (e.g., \"low,\" \"medium,\" \"high\").\n",
        "    * **Nominal**: Categories without a meaningful order (as with `df_object`).\n",
        "    * **Memory Efficient**: Internally stores an integer representation of each category, which is more efficient for storage and computation.\n",
        "\n",
        "**Categorical Features**\n",
        "\n",
        "This is a combined group of columns from both the `category` and `object` data types. These columns represent features that are **not** numerical and will likely need to be converted to a numerical format using encoding techniques (like **One-Hot Encoding** or **Label Encoding**) before being used in most machine learning models.\n",
        "\n",
        "* **Characteristics**:\n",
        "    * **Mixed Types**: A collection of both `category` and `object` data types.\n",
        "    * **Preprocessing Required**: These features cannot be directly used in most machine learning algorithms. They must be preprocessed to a numerical representation.\n",
        "    * **High-level Representation**: This group represents all the columns in a dataset that are qualitative rather than quantitative."
      ],
      "metadata": {
        "id": "nMZvDVF51DcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_numerical = df.select_dtypes(include='number').columns\n",
        "# df_object = df.select_dtypes(include=['object']).columns\n",
        "# df_discreet = df.select_dtypes(include=['category']).columns\n",
        "# df_categorical_features = df.select_dtypes(include=['category', 'object']).columns\n",
        "# print(\"Numerical Data:\")\n",
        "# print(df_numerical)\n",
        "# print(\"/nObject Data:\")\n",
        "# print(df_object)\n",
        "# print(\"/nDiscreet Data:\")\n",
        "# print(df_discreet)\n",
        "# print(\"/nCategorical Data:\")\n",
        "# print(df_categorical_features"
      ],
      "metadata": {
        "id": "pVRA3GCN73QV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Row Duplicates"
      ],
      "metadata": {
        "id": "YIpg3h9QFswd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first identify and then delete any row duplicates"
      ],
      "metadata": {
        "id": "Pf0GiiFiFwNu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Column Duplicates\n"
      ],
      "metadata": {
        "id": "Putqz0nUF-sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first identify and then delete duplicate features"
      ],
      "metadata": {
        "id": "7qKp-5peGBcn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants\n",
        "\n",
        "Features with constant values should be deleted because they provide **zero information or predictive power** to a machine learning model.\n",
        "\n",
        "* **The Problem:** Machine learning models, especially those based on statistical principles (like regression) or information theory (like decision trees), rely on **variance** or **differences** in the data to learn relationships.\n",
        "* **The Effect:** A feature where *every* row has the exact same value (e.g., a column called `Country` where every value is 'USA') cannot help distinguish one data point (row) from another. It offers no insight into why the target variable (what you are trying to predict) changes.\n",
        "    * **Analogy:** Imagine trying to predict a student's grade based on whether they attended a school. If *every* student in your dataset attended a school, that \"attended school\" feature is useless for predicting grades.\n",
        "* **Mathematical Issue:** Many machine learning algorithms involve calculations based on the standard deviation or variance of features.\n",
        "    * For example, in standardizing data (a common preprocessing step), you divide by the standard deviation: $z = \\frac{x - \\mu}{\\sigma}$.\n",
        "    * If a feature is constant, its standard deviation ($\\sigma$) is **zero**. **Dividing by zero** is mathematically undefined and will cause algorithms to fail, raise errors, or produce unstable results.\n",
        "\n",
        "* **The Benefit:** While a single constant column doesn't add much overhead, in datasets with hundreds or thousands of features, removing all zero-variance columns is a form of **dimensionality reduction**.\n",
        "* **The Result:** Removing these irrelevant features speeds up model training and prediction times, and reduces memory usage, all without any loss in predictive performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xw5iD_SG-3TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first identify and then delete any constants"
      ],
      "metadata": {
        "id": "nuB6RAHuDvGX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quasi-Constants\n",
        "\n",
        "A quasi-constant feature is a feature (column) where **a single value is present for a vast majority of the observations** (rows), but not *all* of them.\n",
        "\n",
        "* **Constant Feature:** 100% of values are the same. (e.g., all 1s)\n",
        "* **Quasi-Constant Feature:** 99.5% of values are the same, and the remaining 0.5% are different. (e.g., 995 rows are 'A', 5 rows are 'B')\n",
        "\n",
        "We delete quasi constant values because **they provide extremely little predictive value** but increase model complexity and computational cost.\n",
        "\n",
        "1.  **Low Information:** The small variations have minimal, if any, predictive power because they affect only a tiny fraction of the dataset.\n",
        "2.  **Overfitting Risk:** Including features that are mostly constant might occasionally cause a complex model to *overfit* to the few rare non-constant values, learning noise instead of the general pattern.\n",
        "3.  **Efficiency:** Removing them is a straightforward way to reduce the dimensionality of your dataset without meaningfully impacting the model's performance.\n",
        "\n",
        "Because \"quasi-constant\" is a subjective term, you must define a **threshold** to decide when a feature has too little variance to be useful. This threshold is based on the **percentage of the most frequent value (mode)**.\n",
        "\n",
        "There is **no single, universally mandatory percentage**. The threshold is a **hyperparameter** that you, the data scientist, must tune based on your project, dataset size, and modeling goals.\n",
        "\n",
        "Commonly cited thresholds in the data science community are usually very high, indicating a strong consensus that the value should be *almost* constant:\n",
        "\n",
        "| Common Threshold Range | Meaning |\n",
        "| :--- | :--- |\n",
        "| **95%** | If one value makes up 95% or more of the data, drop the feature. |\n",
        "| **98%** | If one value makes up 98% or more of the data, drop the feature. |\n",
        "| **99% - 99.9%** | **Most frequently recommended starting point,** especially for large datasets. |\n",
        "\n",
        "Use 95% for this exercise\n"
      ],
      "metadata": {
        "id": "I2e8lgeTEtuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first identify and then delete any quasi constants"
      ],
      "metadata": {
        "id": "7qA2qwEWFUjD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Values (Imputation)"
      ],
      "metadata": {
        "id": "DaK5E7BEHrdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all missing data must be replaced with a meaningful value. Explain your reasoning."
      ],
      "metadata": {
        "id": "SXPp9Oqbqg9-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outliers"
      ],
      "metadata": {
        "id": "qzuW_Dp-h0hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# handle outliers"
      ],
      "metadata": {
        "id": "Wvt9mNhQvX2C"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datetime"
      ],
      "metadata": {
        "id": "9XexLNUgPwi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# are there any features that need datetime consideration?"
      ],
      "metadata": {
        "id": "E_8HWJqR5mMJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Creation"
      ],
      "metadata": {
        "id": "3ZaEp01sx2-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new variable by combining two variables"
      ],
      "metadata": {
        "id": "l4TygZ-hx6PX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discretization"
      ],
      "metadata": {
        "id": "Ppg8LVqXP7Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# any features that need to be discretized?"
      ],
      "metadata": {
        "id": "5B1kUXQt2fWV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28c3f668"
      },
      "source": [
        "## Categorical Encoding\n",
        "* Sklearn One Hot Encoding\n",
        "* Dummy Trap\n",
        "* Pandas get_dummies\n",
        "* Labelizer\n",
        "* Weight of Evidence\n",
        "* Frequency Encoding\n",
        "\n",
        "### Categorical Data\n",
        "* Nominal (Cat or Dog)\n",
        "* Ordinal (Grades)\n",
        "* Works better for limited labels in a category\n",
        "* Engineer features with many labels\n",
        "\n",
        "### Multicollinearity\n",
        "* Predictors need to be independent of each other\n",
        "* https://www.theanalysisfactor.com/multicollinearity-explained-visually/\n",
        "* https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/\n",
        "* Cats_and_Dogs = [Cat, Dog, Dog, Cat, Cat, Dog]\n",
        "* Cats = [1, 0, 0, 1, 1, 0]\n",
        "* Dogs = [0, 1, 1, 0, 0, 1]\n",
        "\n",
        "### Beware of Mismatch in Training and Test\n",
        "\n",
        "* Some labels in the train set don't show up in the test set\n",
        "\n",
        "https://towardsdatascience.com/beware-of-the-dummy-variable-trap-in-pandas-727e8e6b8bde"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimensionality\n",
        "\n",
        "One-hot encoding creates a new binary column for each unique category in a categorical feature. The main problem with this is the **curse of dimensionality**, especially for features with many unique values (high cardinality).\n",
        "\n",
        "This process rapidly increases the number of columns in your dataset, leading to several issues:\n",
        "\n",
        "* **Increased Memory and Computational Costs**: The dataset becomes much larger, requiring more memory and computational power to store and process, which slows down model training.\n",
        "* **Sparse Data**: The new columns are mostly zeros, creating a **sparse matrix** where only one value is a \"1\" in each row for that set of features. This can be inefficient for many algorithms that don't handle sparsity well.\n",
        "* **Overfitting**: With a high number of features and potentially limited data, models can easily learn the noise and idiosyncrasies of the training data rather than the underlying patterns, leading to poor performance on new, unseen data."
      ],
      "metadata": {
        "id": "-2T9cgDu8s34"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eaf9f4e"
      },
      "source": [
        "### Dummy Trap\n",
        "\n",
        "The Dummy Variable Trap occurs when two or more dummy variables created by one-hot encoding are highly correlated (multi-collinear). This means that one variable can be predicted from the others, making it difficult to interpret predicted coefficient variables in regression models. In other words, the individual effect of the dummy variables on the prediction model can not be interpreted well because of multicollinearity.\n",
        "\n",
        "https://www.learndatasci.com/glossary/dummy-variable-trap/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **dummy trap** is a problem that occurs in regression analysis when a categorical variable with multiple categories is encoded into dummy variables. It creates a situation of **perfect multicollinearity**, where one dummy variable can be perfectly predicted from a linear combination of the other dummy variables.\n",
        "\n",
        "**How It Happens**\n",
        "\n",
        "When you use a technique like **one-hot encoding** to convert a categorical variable (e.g., \"City\" with categories \"New York,\" \"Chicago,\" and \"Boston\") into numerical data, you create a new binary column for each category. For any given data point, one of these new columns will be a `1` and the rest will be `0`s.\n",
        "\n",
        "* **Example**: If you have three cities, you create three dummy variables: `is_New_York`, `is_Chicago`, and `is_Boston`. A row for a person in New York would have `is_New_York` = 1, `is_Chicago` = 0, and `is_Boston` = 0.\n",
        "\n",
        "The trap arises because there's a **redundant variable**. If you know the values for `is_New_York` and `is_Chicago`, you can perfectly predict the value for `is_Boston`: if `is_New_York` is 0 and `is_Chicago` is 0, then `is_Boston` must be 1. This linear relationship between the variables violates a key assumption of many regression models (like linear regression), making it impossible to uniquely calculate the coefficients for each variable.\n",
        "\n",
        "### The Solution\n",
        "\n",
        "To avoid the dummy trap, you must **drop one of the dummy variables**. This is also known as using \"dummy encoding\" instead of one-hot encoding. By having only $k-1$ dummy variables for a categorical variable with $k$ categories, you eliminate the perfect multicollinearity. The dropped category becomes the **baseline** or **reference category**, and the coefficients of the remaining dummy variables are interpreted in comparison to that baseline."
      ],
      "metadata": {
        "id": "e2pwIGwFWjQC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45820551"
      },
      "source": [
        "### One Hot Encoding Alternatives\n",
        "\n",
        "For features with many labels\n",
        "\n",
        "* https://medium.com/analytics-vidhya/stop-one-hot-encoding-your-categorical-variables-bbb0fba89809\n",
        "* https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4\n",
        "* https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02 (frequency and mean encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38db741f"
      },
      "source": [
        "### Encoding Order\n",
        "\n",
        "* Bilabel Mapping (2 labels)\n",
        "* Frequency (5+ labels)\n",
        "* One Hot Encoding (3 - 5 labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7f408874"
      },
      "outputs": [],
      "source": [
        "# encode features that need it"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation\n",
        "\n",
        "Correlation is a statistical measure in data science that quantifies the **linear relationship** between two variables. It helps you understand if and how two variables change together. This relationship is measured by the **correlation coefficient**, a value typically denoted by **r** that ranges from -1 to +1.\n",
        "\n",
        "**Types of Correlation**\n",
        "\n",
        "* **Positive Correlation (r > 0):** As one variable increases, the other also tends to increase. For example, the more hours a student studies, the higher their exam score tends to be.\n",
        "* **Negative Correlation (r < 0):** As one variable increases, the other tends to decrease. For example, as the temperature rises, the sales of hot coffee might decrease.\n",
        "* **No Correlation (r ≈ 0):** There is no apparent linear relationship between the two variables. For instance, the number of books you read has no correlation with the color of your car.\n",
        "\n",
        "\n",
        "**Key Aspects**\n",
        "\n",
        "* **Strength:** The closer the absolute value of the correlation coefficient is to 1, the stronger the linear relationship. A value of 1 or -1 indicates a perfect linear relationship. The closer the value is to 0, the weaker the relationship.\n",
        "* **Direction:** The sign of the coefficient (+ or -) indicates the direction of the relationship.\n",
        "* **Correlation does not imply causation:** This is a crucial point in data science. Just because two variables are correlated doesn't mean one causes the other. There could be a third, unobserved variable (a confounding variable) influencing both, or the relationship could be a mere coincidence."
      ],
      "metadata": {
        "id": "LA6WVjH64v7g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2271c79c"
      },
      "outputs": [],
      "source": [
        "# delete or derive features that are highly correlated with each other"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Day of Week Encoding\n",
        "\n",
        "* https://mikulskibartosz.name/time-in-machine-learning\n",
        "\n",
        "The best way to encode days of the week for machine learning depends on whether the model can recognize and use the inherent **cyclical** nature of the data. The two most effective methods are **one-hot encoding** and **sinusoidal (or cyclical) encoding**.\n",
        "\n",
        "**One-Hot Encoding**\n",
        "One-hot encoding is a straightforward method that creates a new binary column for each day of the week. This is an excellent choice for models that don't inherently handle cyclical data well, such as linear regression and tree-based models (e.g., Random Forest, Gradient Boosting).\n",
        "\n",
        "* **How it works**: A feature like \"Day of Week\" with values like 'Monday', 'Tuesday', etc., is transformed into 7 new columns: `is_Monday`, `is_Tuesday`, etc. For a given row, the column corresponding to the correct day will have a value of 1, and all other new columns will be 0.\n",
        "* **Pros**:\n",
        "    * Simple and easy to implement.\n",
        "    * Works with virtually all machine learning models.\n",
        "    * Prevents the model from incorrectly assuming an ordinal relationship (e.g., thinking that Saturday is \"less than\" Sunday).\n",
        "* **Cons**:\n",
        "    * Can create a large number of features, especially for data with high cardinality.\n",
        "    * Doesn't capture the cyclical relationship of the days (e.g., Sunday is closer to Monday than to Wednesday).\n",
        "\n",
        "**Sinusoidal (Cyclical) Encoding**\n",
        "\n",
        "This method is ideal for models that can leverage the continuous, cyclical nature of the data, such as neural networks. It transforms the day of the week into two new features using sine and cosine functions.\n",
        "\n",
        "* **How it works**: Each day is mapped to an angle on a circle. Monday might be 0 degrees, Tuesday 51.4 degrees ($360/7$), and so on, with Sunday wrapping back around to Monday. The sine and cosine of these angles are then used as two new features. The formulas are:\n",
        "    * $Sine\\_Feature = sin(\\frac{2 \\pi \\times day\\_of\\_week}{7})$\n",
        "    * $Cosine\\_Feature = cos(\\frac{2 \\pi \\times day\\_of\\_week}{7})$\n",
        "    \n",
        "    This creates a continuous representation where the distance between days is preserved, and the cyclical nature is explicitly encoded.\n",
        "* **Pros**:\n",
        "    * Explicitly captures the cyclical relationship, which can improve model performance.\n",
        "    * Creates only two new features, regardless of the number of days, reducing dimensionality.\n",
        "* **Cons**:\n",
        "    * Can be more complex to implement than one-hot encoding.\n",
        "    * The model must be able to effectively use these continuous features.\n",
        "    * Less interpretable than one-hot encoding.\n",
        "\n",
        "**Recommendation**\n",
        "For a majority of cases, **one-hot encoding** is a safe and reliable choice, especially for tree-based models and simpler linear models. It ensures no false ordinal relationships are introduced. However, if you are using a neural network or a model that benefits from continuous, cyclical features, **sinusoidal encoding** is the better and more elegant solution as it directly encodes the underlying structure of the data."
      ],
      "metadata": {
        "id": "6yia75mH8p43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# any features that need special consideration"
      ],
      "metadata": {
        "id": "nPdE_QawKTMi"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling and Feature Selection\n",
        "\n",
        "The overall goal is to prepare your cleaned data for two different types of modeling and then execute those models, focusing heavily on feature justification and metric reporting.\n",
        "\n",
        "### **Phase 1: Data Preparation and Dependent Variable Definition**\n",
        "\n",
        "The first essential step is ensuring your single, cleaned dataset is set up for the two distinct modeling approaches required.\n",
        "\n",
        "**Action 1: Identify the Two Dependent Variables ($\\text{Y}$ Variables)**\n",
        "\n",
        "Your final cleaned dataset should contain two dependent variables:\n",
        "\n",
        "1.  **$\\text{Y}_{\\text{Continuous}}$:** This must be a dependent variable that is suitable for linear regression.\n",
        "2.  **$\\text{Y}_{\\text{Binary}}$:** This must be a dependent variable that is suitable for logistic regression.\n",
        "\n",
        "### **Phase 2: Model Execution and Feature Selection**\n",
        "\n",
        "You will now treat the Linear Regression and Logistic Regression as two independent sub-projects.\n",
        "\n",
        "#### **Sub-Project A: Linear Regression**\n",
        "\n",
        "**Action 2: Build the Linear Model**\n",
        "Train a complete **Linear Regression** model using your independent features to predict $\\text{Y}_{\\text{Continuous}}$.\n",
        "\n",
        "**Action 3: Select and Justify Top 5 Features**\n",
        "Select the five independent features that provide the most explanatory power for the continuous dependent variable. You must explicitly state and justify your selection method.\n",
        "\n",
        "#### **Sub-Project B: Logistic Regression**\n",
        "\n",
        "**Action 4: Build the Logistic Model**\n",
        "Train a complete **Logistic Regression** model using your independent features to predict $\\text{Y}_{\\text{Binary}}$.\n",
        "\n",
        "**Action 5: Select and Justify Top 5 Features**\n",
        "Select the five independent features that contribute the most to the model's ability to discriminate between the two classes of $\\text{Y}_{\\text{Binary}}$. As with the linear model, you must clearly state and justify the method used.\n",
        "\n",
        "### **Phase 3: Model Evaluation and Reporting**\n",
        "\n",
        "For each model, you must show the appropriate industry-standard metrics.\n",
        "\n",
        "**Action 6: Report Linear Model Metrics**\n",
        "Present the key performance indicators for your Linear Regression model. Summarize all your findings.\n",
        "\n",
        "**Action 7: Report Logistic Model Metrics**\n",
        "Present the key performance indicators for your Logistic Regression model. Summarize all your findings.\n"
      ],
      "metadata": {
        "id": "Gi0z0wi46rGt"
      }
    }
  ]
}